{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RdMxrgspK9lBNtuDhi_MOfOfHhv2TXbP",
      "authorship_tag": "ABX9TyNsJXlciYVJ8kJY8d34ZAKG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c30c463a2746424a99b918b6eb6088cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13ff59bc6d2248a6a7be820e6a4ef001",
              "IPY_MODEL_e22e9c57c2564ec4812715aac77b611e"
            ],
            "layout": "IPY_MODEL_bd5a1fec1cf947769d0b578d92f1ba45"
          }
        },
        "13ff59bc6d2248a6a7be820e6a4ef001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69ac8a4b1b3d4f7fa2558684422d6eea",
            "placeholder": "​",
            "style": "IPY_MODEL_d906cb64797049cab74e3a8f8e83cabb",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "e22e9c57c2564ec4812715aac77b611e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593f2ab7d5fc4be2bfcefbaac0483f19",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5e3c684fd46448681f737154c52e274",
            "value": 1
          }
        },
        "bd5a1fec1cf947769d0b578d92f1ba45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69ac8a4b1b3d4f7fa2558684422d6eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d906cb64797049cab74e3a8f8e83cabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "593f2ab7d5fc4be2bfcefbaac0483f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e3c684fd46448681f737154c52e274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de7d3822c5454b31a19594e88e6c7be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a148929f213a40019e941da1ceea3055",
              "IPY_MODEL_4f13efd8fec2428dab3c674c8976f990"
            ],
            "layout": "IPY_MODEL_690621fcf67e45a98ad45c698bf55676"
          }
        },
        "a148929f213a40019e941da1ceea3055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1211c14f57446cbb7ed7141356d473b",
            "placeholder": "​",
            "style": "IPY_MODEL_19402b002b6d4740b9fa96c714b85f11",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "4f13efd8fec2428dab3c674c8976f990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3467ebd8e5a84a079a396eae8f8cd4c6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1835e3cbab624c71a5d2fb600665b5a9",
            "value": 1
          }
        },
        "690621fcf67e45a98ad45c698bf55676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1211c14f57446cbb7ed7141356d473b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19402b002b6d4740b9fa96c714b85f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3467ebd8e5a84a079a396eae8f8cd4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1835e3cbab624c71a5d2fb600665b5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8bd36406b354275becdd3dabd8e63a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9ea7a9c02c24662a65c857661d2654b",
              "IPY_MODEL_14d2b8addda94d7ebd34d5e31eff1d25"
            ],
            "layout": "IPY_MODEL_929e286d931d426b9b0a3a0a634e1cfd"
          }
        },
        "c9ea7a9c02c24662a65c857661d2654b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35308454641a4497a474dda408fef7de",
            "placeholder": "​",
            "style": "IPY_MODEL_53b7a4f5fff54f17982542405b8507e0",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "14d2b8addda94d7ebd34d5e31eff1d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b41af8b0dfa438e89b6739cda92a9c5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e7e65bde4a1465bae4ff10c3c22c09d",
            "value": 1
          }
        },
        "929e286d931d426b9b0a3a0a634e1cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35308454641a4497a474dda408fef7de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b7a4f5fff54f17982542405b8507e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b41af8b0dfa438e89b6739cda92a9c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7e65bde4a1465bae4ff10c3c22c09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VrijKun/CS6910_Assignment_2/blob/main/Assignment_2_DL_ED23D015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Part A and Part B of this assignment you will build and experiment with CNN based image classifiers using a subset of the iNaturalist dataset. In Part C you will take a pre-trained object detection model and use it for a novel application."
      ],
      "metadata": {
        "id": "-OdaiLPxnVqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOfu8JkH5KN3",
        "outputId": "ffeda4bb-6349-4995-a2a6-be7060bf66f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.10.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.13.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dn4LSil7nJ3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c0922b-b343-47c1-e312-2a05fe13cf8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functionals\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "import pytorch_lightning as pyligtining\n",
        "print(pyligtining.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1 (5 Marks)\n",
        "Build a small CNN model consisting of 5 convolution layers. Each convolution layer would be followed by a ReLU activation and a max pooling layer. Here is sample code for building one such conv-relu-maxpool block in keras.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "After 5 such conv-relu-maxpool blocks of layers you should have one dense layer followed by the output layer containing 10 neurons (1 for each of the 10 classes). The input layer should be compatible with the images in the iNaturalist dataset.\n",
        "\n",
        "**The code should be flexible such that the number of filters, size of filters and activation function in each layer can be changed. You should also be able to change the number of neurons in the dense layer.**\n",
        "\n",
        "(a) What is the total number of computations done by your network? (assume mmm filters in each layer of size k×kk\\times kk×k and nnn neurons in the dense layer)\n",
        "\n",
        "(b) What is the total number of parameters in your network? (assume mmm filters in each layer of size k×kk\\times kk×k and nnn neurons in the dense layer)\n"
      ],
      "metadata": {
        "id": "0HWpx8UNpW8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "wget.download('https://storage.googleapis.com/wandb_datasets/nature_12K.zip')\n",
        "!unzip /content/nature_12K.zip"
      ],
      "metadata": {
        "id": "xb0EUN4ghIvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad23eef-69f8-41cf-a694-f9362ea0489c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Archive:  /content/nature_12K.zip\n",
            "replace inaturalist_12K/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import datasets, transforms\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "class ECNN(pl.LightningModule):\n",
        "    def __init__(self, input_shape, num_classes, num_filters, filter_size, dense_neurons, batch_normalization, batch_size, dropout, activation):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        #print(self.input_shape)\n",
        "        self.num_classes = num_classes\n",
        "        self.num_filters = num_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.dense_neurons = dense_neurons\n",
        "        self.activation = activation\n",
        "        self.batch_normalization=batch_normalization\n",
        "\n",
        "        # Define convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, num_filters[0], filter_size[0])\n",
        "        self.conv2 = nn.Conv2d(num_filters[0], num_filters[1], filter_size[1])\n",
        "        self.conv3 = nn.Conv2d(num_filters[1], num_filters[2], filter_size[2])\n",
        "        self.conv4 = nn.Conv2d(num_filters[2], num_filters[3], filter_size[3])\n",
        "        self.conv5 = nn.Conv2d(num_filters[3], num_filters[4], filter_size[4])\n",
        "\n",
        "        # Defining batch normalization\n",
        "        self.bn1 = nn.BatchNorm2d(num_filters[0])\n",
        "        self.bn2 = nn.BatchNorm2d(num_filters[1])\n",
        "        self.bn3 = nn.BatchNorm2d(num_filters[2])\n",
        "        self.bn4 = nn.BatchNorm2d(num_filters[3])\n",
        "        self.bn5 = nn.BatchNorm2d(num_filters[4])\n",
        "\n",
        "\n",
        "        # Define pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Define dropout\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "        self.dropout4 = nn.Dropout(dropout)\n",
        "        self.dropout5 = nn.Dropout(dropout)\n",
        "\n",
        "        # Calculate the size of the feature maps after max pooling\n",
        "        self.flatten_size = self.calculate_flatten_size()\n",
        "\n",
        "        # Define dense layers\n",
        "        self.fc1 = nn.Linear(self.flatten_size, dense_neurons)\n",
        "        self.fc2 = nn.Linear(dense_neurons, num_classes)\n",
        "\n",
        "    '''\n",
        "    ########################################\n",
        "    def forward(self, x):\n",
        "        for conv, bn in zip(self.conv_layers, self.bn_layers):\n",
        "            x = F.relu(bn(conv(x)))\n",
        "            x = self.pool(x)\n",
        "        x = x.view(-1, self.flatten_size)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def calculate_flatten_size(self):\n",
        "        # Dummy input to calculate the size of the feature maps after max pooling\n",
        "        x = torch.randn(1, *self.input_shape)\n",
        "        for conv, bn in zip(self.conv_layers, self.bn_layers):\n",
        "            x = F.relu(bn(conv(x)))\n",
        "            x = self.pool(x)\n",
        "        return x.view(x.size(0), -1).size(1)\n",
        "\n",
        "    #####################################\n",
        "    '''\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.batch_normalization:\n",
        "          x = F.relu(self.bn1(self.conv1(x)))\n",
        "        else:\n",
        "          x = F.relu(self.conv1(x))\n",
        "        x=self.dropout1(x)\n",
        "        x = self.pool(x)\n",
        "        #print('0: ',x.shape)\n",
        "\n",
        "        if self.batch_normalization:\n",
        "          x = F.relu(self.bn2(self.conv2(x)))\n",
        "        else:\n",
        "          x = F.relu(self.conv2(x))\n",
        "        x=self.dropout2(x)\n",
        "        x = self.pool(x)\n",
        "        #print('1: ',x.shape)\n",
        "\n",
        "        if self.batch_normalization:\n",
        "          x = F.relu(self.bn3(self.conv3(x)))\n",
        "        else:\n",
        "          x = F.relu(self.conv3(x))\n",
        "        x=self.dropout3(x)\n",
        "        x = self.pool(x)\n",
        "        #print('2: ',x.shape)\n",
        "\n",
        "        if self.batch_normalization:\n",
        "          x = F.relu(self.bn4(self.conv4(x)))\n",
        "        else:\n",
        "          x = F.relu(self.conv4(x))\n",
        "        x=self.dropout4(x)\n",
        "        x = self.pool(x)\n",
        "        #print('3: ',x.shape)\n",
        "\n",
        "        if self.batch_normalization:\n",
        "          x = F.relu(self.bn5(self.conv5(x)))\n",
        "        else:\n",
        "          x = F.relu(self.conv5(x))\n",
        "        x=self.dropout5(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #print('5: ',x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        #print('5.5: ',x.shape)\n",
        "        x = F.log_softmax(x, dim=1) # trying if it works\n",
        "        #return F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "    def calculate_flatten_size(self):\n",
        "\n",
        "        x = torch.randn(1, *self.input_shape)\n",
        "        x = self.pool(self.conv1(x))\n",
        "        x = self.pool(self.conv2(x))\n",
        "        x = self.pool(self.conv3(x))\n",
        "        x = self.pool(self.conv4(x))\n",
        "        x = self.pool(self.conv5(x))\n",
        "        return x.view(x.size(0), -1).size(1)\n",
        "\n",
        "        '''\n",
        "        print('3: ',x.shape)\n",
        "        x = self.pool(self.conv4(x))\n",
        "        print('4: ',x.shape)\n",
        "        x = self.pool(self.conv5(x))\n",
        "        print('5: ',x.shape)\n",
        "        return x.view(x.size(0), -1).size(1)\n",
        "        '''\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "    def training_step(self, train_loader):\n",
        "        x, y = train_loader\n",
        "        y_hat = self(x)\n",
        "        loss = F.nll_loss(y_hat, y)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, val_loader):\n",
        "        x, y = val_loader\n",
        "        y_hat = self(x)\n",
        "        loss = F.nll_loss(y_hat, y)\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def test_step(self, test_loader):\n",
        "        x, y = test_loader\n",
        "        y_hat = self(x)\n",
        "        loss = F.nll_loss(y_hat, y)\n",
        "        self.log('test_loss', loss)\n",
        "\n",
        "    def accuracy(y_hat, y):\n",
        "        preds = torch.argmax(y_hat, dim=1)\n",
        "        correct = (preds == y).sum().item()\n",
        "        total = y.size(0)\n",
        "        acc = correct / total\n",
        "        return acc\n",
        "\n",
        "    def validation_accuracy(model, val_loader):\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                x, y = batch\n",
        "                y_hat = model(x)\n",
        "                correct += (torch.argmax(y_hat, dim=1) == y).sum().item()\n",
        "                total += y.size(0)\n",
        "        acc = correct / total\n",
        "        return acc\n",
        "\n",
        "    def test_accuracy(model, test_loader):\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                x, y = batch\n",
        "                y_hat = model(x)\n",
        "                correct += (torch.argmax(y_hat, dim=1) == y).sum().item()\n",
        "                total += y.size(0)\n",
        "        acc = correct / total\n",
        "        return acc\n",
        "\n",
        "    '''\n",
        "    def on_validation_epoch_end(self, x): # outputs\n",
        "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        self.log('val_loss', avg_loss)\n",
        "        val_acc = self.validation_accuracy(val_loader)\n",
        "        self.log('val_accuracy', val_acc, prog_bar=True)\n",
        "        print(f'Validation Accuracy: {val_acc:.4f}')\n",
        "\n",
        "    def on_train_epoch_end(self, x): # outputs\n",
        "        avg_loss = torch.stack([x['train_loss'] for x in outputs]).mean()\n",
        "        self.log('train_loss', avg_loss)\n",
        "        train_acc = self.accuracy(train_loader)\n",
        "        self.log('train_accuracy', train_acc, prog_bar=True)\n",
        "        print(f'Training Accuracy: {train_acc:.4f}')\n",
        "    '''\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# New Load dataset\n",
        "train_dataset = ImageFolder('/content/inaturalist_12K/train', transform=transform)\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
        "test_data = ImageFolder('/content/inaturalist_12K/val', transform=transform)\n",
        "\n",
        "\n",
        "# Old Load dataset\n",
        "'''\n",
        "train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/nature_12K/inaturalist_12K/train', transform=transform)\n",
        "test_data =  datasets.ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/nature_12K/inaturalist_12K/val', transform=transform)\n",
        "'''\n",
        "\n",
        "# Create data loaders\n",
        "\n",
        "def create_data_loaders(train_data, val_data, batch_size, shuffle_train=True, pin_memory=True, num_workers=2):\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle_train, pin_memory=pin_memory, num_workers=num_workers)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, pin_memory=pin_memory, num_workers=num_workers)\n",
        "    return train_loader, val_loader\n",
        "\n",
        "train_loader, val_loader = create_data_loaders(train_data, val_data, batch_size = 32, shuffle_train=True)\n",
        "'''\n",
        "batch_size= 32\n",
        "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size= batch_size)\n",
        "\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "model = ECNN(input_shape=(3, 224, 224), num_classes=10, num_filters=[32,32,32,32,32], filter_size=[3,3,3,3,3], dense_neurons=128,batch_normalization= True, batch_size = 32,dropout=0.2 ,activation='relu')\n",
        "#x = torch.randn(1,3,224,224)\n",
        "#x = torch.randn(32,3,224,224)\n",
        "#a =model(x)\n",
        "#print(a.shape)\n",
        "\n",
        "# Initialize Lightning trainer with GPU support\n",
        "trainer = pyligtining.Trainer(max_epochs=1, accelerator=\"auto\") # not GPU but accelerator\n",
        "\n",
        "# Train the model\n",
        "trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "print(model.validation_accuracy(train_loader))\n",
        "print(model.validation_accuracy(val_loader))\n",
        "\n",
        "# Test the model\n",
        "#trainer.test(model, val_loader)\n",
        "#print(model.test_accuracy(val_loader))\n",
        "'''"
      ],
      "metadata": {
        "id": "DQdLpMsgbZfS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "84c2ff46-5808-4e81-9b7a-054ac2fc9fc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nbatch_size= 32\\ntrain_loader = DataLoader(train_data, batch_size = batch_size, shuffle=True)\\nval_loader = DataLoader(val_data, batch_size= batch_size)\\n\\n\\n\\n# Initialize model\\nmodel = ECNN(input_shape=(3, 224, 224), num_classes=10, num_filters=[32,32,32,32,32], filter_size=[3,3,3,3,3], dense_neurons=128,batch_normalization= True, batch_size = 32,dropout=0.2 ,activation=\\'relu\\')\\n#x = torch.randn(1,3,224,224)\\n#x = torch.randn(32,3,224,224)\\n#a =model(x)\\n#print(a.shape)\\n\\n# Initialize Lightning trainer with GPU support\\ntrainer = pyligtining.Trainer(max_epochs=1, accelerator=\"auto\") # not GPU but accelerator\\n\\n# Train the model\\ntrainer.fit(model, train_loader, val_loader)\\n\\nprint(model.validation_accuracy(train_loader))\\nprint(model.validation_accuracy(val_loader))\\n\\n# Test the model\\n#trainer.test(model, val_loader)\\n#print(model.test_accuracy(val_loader))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sweep Iteration 1"
      ],
      "metadata": {
        "id": "E2tkvSX13wuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb sweep\n",
        "!pip install --upgrade wandb\n",
        "!wandb login 3c21150eb43b007ee446a1ff6e87f640ec7528c4 #my API key for wandb login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I0876QmF9GA",
        "outputId": "3d841740-05c4-498d-e994-6244c96fd327"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.44.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BFIefz7Epeng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pyligtining\n",
        "import wandb\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'bayes', #grid, random,bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'activation': {\n",
        "            'values': ['relu','gelu','elu','silu']\n",
        "        },\n",
        "        'num_filter': {\n",
        "            'values': [[32,32,32,32,32] ,[64,64,64,64,64] ,[128,128,128,128,128],\n",
        "                       [64,128,256,512,1024]]\n",
        "        },\n",
        "        'filter_size':{\n",
        "            'values':[[3,3,3,5,5],[5,5,5,5,5],[3,3,3,3,3]]\n",
        "        },\n",
        "        'dropout':{\n",
        "            'values':[0.2,0.3]\n",
        "        },\n",
        "        'batch_normal':{\n",
        "            'values':[True,False]\n",
        "        },\n",
        "        'batch_size':{\n",
        "            'values':[32,64]\n",
        "        },\n",
        "        'data_augmentation':{\n",
        "            'values':[True,False]\n",
        "        },\n",
        "        'input_shape':{\n",
        "            'values':[(3, 224, 224)]\n",
        "        },\n",
        "        'num_classes':{\n",
        "            'values': [10]\n",
        "        },\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity='ed23d015', project=\"DL_Assignment_2\")\n",
        "\n",
        "def sweep_train():\n",
        "  # Default hyper-parameters\n",
        "  config_defaults = {\n",
        "      'activation':'relu',\n",
        "      'num_filter':[32,32,32,32,32],\n",
        "      'filter_size':[3,3,3,3,3],\n",
        "      'dropout':0.3,\n",
        "      'batch_normal':True,\n",
        "      'batch_sizze': 32,\n",
        "      'data_augmentation':True,\n",
        "      'input_shape':(3, 224, 224),\n",
        "      'num_classes': 10,\n",
        "  }\n",
        "\n",
        "  # Initialize wandb run\n",
        "  wandb.init(project='DL_Assignment_2', entity='ed23d015',config=config_defaults)\n",
        "  wandb.run.name = 'act:'+ str(wandb.config.activation)+' ;filter:'+str(wandb.config.num_filter)+ ' ;ker:'+str(wandb.config.filter_size)+ ' ;drop:'+str(wandb.config.dropout)+' ;b_n:'+str(wandb.config.batch_normal) +' ;b_s:'+str(wandb.config.batch_size)+' ;d_a:'+str(wandb.config.data_augmentation)\n",
        "\n",
        "  config = wandb.config\n",
        "  activation = config.activation\n",
        "  num_filter = config.num_filter\n",
        "  filter_size = config.filter_size\n",
        "  dropout = config.dropout\n",
        "  batch_normal = config.batch_normal\n",
        "  batch_size = config.batch_size\n",
        "  data_augmentation = config.data_augmentation\n",
        "  input_shape = config.input_shape\n",
        "  num_classes = config.num_classes\n",
        "\n",
        "  train_loader, val_loader = create_data_loaders(train_data, val_data, batch_size, shuffle_train=True, pin_memory=True, num_workers = 2)\n",
        "\n",
        "  model = ECNN(input_shape=input_shape, num_classes=num_classes, num_filters=num_filter, filter_size=filter_size, dense_neurons=128,batch_normalization= batch_normal, batch_size = batch_size, dropout=dropout ,activation=activation)\n",
        "\n",
        "  # Initialize Lightning trainer with GPU support\n",
        "  trainer1 = pl.Trainer(max_epochs=10, accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\", devices = 1 if torch.cuda.is_available() else 2, log_every_n_steps=30, callbacks=[EarlyStopping(monitor='val_loss')])\n",
        "\n",
        "  # Train the model\n",
        "  trainer1.fit(model, train_loader, val_loader)\n",
        "\n",
        "  # Calculating losses and accuracies\n",
        "  train_loss = model.training_step(train_loader)\n",
        "  val_loss = model.validation_step(val_loader)\n",
        "  train_accuracy = model.validation_accuracy(train_loader)\n",
        "  val_accuracy = model.validation_accuracy(val_loader)\n",
        "\n",
        "\n",
        "  # Log metrics to wandb\n",
        "  wandb.log({\"epoch\": epoch + 1, \"train_loss\": train_loss, \"train_accuracy\": train_accuracy, \"model.\": val_loss, \"val_accuracy\": val_accuracy})\n",
        "\n",
        "  # Print training progress\n",
        "  print(f\"Epoch {epoch + 1}/{trainer1.max_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "  '''\n",
        "  # It's training time\n",
        "\n",
        "  model = ECNN(input_shape=(3, 224, 224), num_classes=10, num_filters=num_filter, filter_size=filter_size, dense_neurons=128, batch_normalization=batch_normal, batch_size = batch_size  dropout=dropout, activation=activation)\n",
        "\n",
        "  # Initialize Lightning trainer with GPU support\n",
        "  #trainer = pyligtining.Trainer(max_epochs=10, accelerator=\"auto\") # not GPU but accelerator\n",
        "  trainer = pl.Trainer(max_epochs=10, gpus=1 if torch.cuda.is_available() else None, progress_bar_refresh_rate=30, callbacks=[EarlyStopping(monitor='val_loss')])\n",
        "\n",
        "\n",
        "  # Train the model\n",
        "  trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "  # Test the model\n",
        "  #trainer.test()\n",
        "\n",
        "  # Test the model\n",
        "  trainer.test(test_dataloaders=val_loader)\n",
        "  '''\n",
        "# From here\n",
        "\n",
        "  '''\n",
        "  train_loader, val_loader = create_data_loaders(train_data, val_data, batch_size, shuffle_train=True, pin_memory=True, num_workers = 2)\n",
        "  # It's training time\n",
        "  model = ECNN(input_shape=input_shape, num_classes=num_classes, num_filters=num_filter, filter_size=filter_size, dense_neurons=128, batch_normalization=batch_normal, batch_size=batch_size , dropout=dropout, activation=activation)\n",
        "\n",
        "\n",
        "  print('batch_size: ' , batch_size)\n",
        "  # Define loss function and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "  # Initialize Lightning trainer with GPU support\n",
        "  #trainer1 = pl.Trainer(max_epochs=10, accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", progress_bar_refresh_rate=30, callbacks=[EarlyStopping(monitor='val_loss')])\n",
        "  trainer1 = pl.Trainer(max_epochs=10, accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\", devices = 1 if torch.cuda.is_available() else 2, log_every_n_steps=30, callbacks=[EarlyStopping(monitor='val_loss')])\n",
        "\n",
        "  # Initialize Lightning trainer\n",
        "  #trainer1 = pyligtining.Trainer(max_epochs=10, accelerator='auto')#'cpu'\n",
        "  #trainer1 = pl.Trainer(max_epochs=10, gpus = 1 if torch.cuda.is_available() else 0, test_dataloaders=val_loader)\n",
        "  #print('Check point 1')\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in range(trainer1.max_epochs):\n",
        "      # Train the model\n",
        "      model.train()\n",
        "      train_loss = 0.0\n",
        "      correct_train = 0\n",
        "      total_train = 0\n",
        "      #print('Check point 2')\n",
        "      for images, labels in train_loader:\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(images)\n",
        "          #print('Check point 2.1')\n",
        "          loss = criterion(outputs, labels)\n",
        "          #print('Check point 2.2')\n",
        "          loss.backward()\n",
        "          #print('Check point 2.3')\n",
        "          optimizer.step()\n",
        "          #print('Check point 3')\n",
        "          train_loss += loss.item()\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          total_train += labels.size(0)\n",
        "          correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "      train_accuracy = 100 * correct_train / total_train\n",
        "      train_loss /= len(train_loader)\n",
        "      #print('Check point 4')\n",
        "      # Validate the model\n",
        "      model.eval()\n",
        "      val_loss = 0.0\n",
        "      correct_val = 0\n",
        "      total_val = 0\n",
        "      #print('Check point 5')\n",
        "      with torch.no_grad():\n",
        "          for images, labels in val_loader:\n",
        "              outputs = model(images)\n",
        "              loss = criterion(outputs, labels)\n",
        "              val_loss += loss.item()\n",
        "              _, predicted = torch.max(outputs, 1)\n",
        "              total_val += labels.size(0)\n",
        "              correct_val += (predicted == labels).sum().item()\n",
        "              #print('Check point 6')\n",
        "      val_accuracy = 100 * correct_val / total_val\n",
        "      val_loss /= len(val_loader)\n",
        "\n",
        "      # Log metrics to wandb\n",
        "      wandb.log({\"epoch\": epoch + 1, \"train_loss\": train_loss, \"train_accuracy\": train_accuracy, \"val_loss\": val_loss, \"val_accuracy\": val_accuracy})\n",
        "\n",
        "      # Print training progress\n",
        "      print(f\"Epoch {epoch + 1}/{trainer1.max_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "  # Test the model\n",
        "  trainer1.test(test_dataloaders=val_loader)\n",
        "  #trainer1.test()\n",
        "  '''\n",
        "#RUNNING THE SWEEP\n",
        "wandb.agent(sweep_id, function=sweep_train, count=120) #change the number of count here\n",
        "\n",
        "#To here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c30c463a2746424a99b918b6eb6088cf",
            "13ff59bc6d2248a6a7be820e6a4ef001",
            "e22e9c57c2564ec4812715aac77b611e",
            "bd5a1fec1cf947769d0b578d92f1ba45",
            "69ac8a4b1b3d4f7fa2558684422d6eea",
            "d906cb64797049cab74e3a8f8e83cabb",
            "593f2ab7d5fc4be2bfcefbaac0483f19",
            "b5e3c684fd46448681f737154c52e274",
            "de7d3822c5454b31a19594e88e6c7be6",
            "a148929f213a40019e941da1ceea3055",
            "4f13efd8fec2428dab3c674c8976f990",
            "690621fcf67e45a98ad45c698bf55676",
            "b1211c14f57446cbb7ed7141356d473b",
            "19402b002b6d4740b9fa96c714b85f11",
            "3467ebd8e5a84a079a396eae8f8cd4c6",
            "1835e3cbab624c71a5d2fb600665b5a9",
            "d8bd36406b354275becdd3dabd8e63a4",
            "c9ea7a9c02c24662a65c857661d2654b",
            "14d2b8addda94d7ebd34d5e31eff1d25",
            "929e286d931d426b9b0a3a0a634e1cfd",
            "35308454641a4497a474dda408fef7de",
            "53b7a4f5fff54f17982542405b8507e0",
            "5b41af8b0dfa438e89b6739cda92a9c5",
            "7e7e65bde4a1465bae4ff10c3c22c09d"
          ]
        },
        "id": "jTh3obDC3uye",
        "outputId": "9ef76d77-0ad2-4f9b-a708-e282a4f8c990"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: b3qcwh7b\n",
            "Sweep URL: https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: otmejofu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normal: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: [5, 5, 5, 5, 5]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape: [3, 224, 224]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_classes: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filter: [64, 128, 256, 512, 1024]\n",
            "Exception in thread ChkStopThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 286, in check_stop_status\n",
            "Exception in thread IntMsgThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 300, in check_internal_messages\n",
            "    self._loop_check_status(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
            "    local_handle = request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 856, in deliver_internal_messages\n",
            "    return self._deliver_internal_messages(internal_message)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 516, in _deliver_internal_messages\n",
            "    self._loop_check_status(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
            "    return self._deliver_record(record)\n",
            "local_handle = request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 840, in deliver_stop_status\n",
            "    return self._deliver_stop_status(status)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 494, in _deliver_stop_status\n",
            "    return self._deliver_record(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n",
            "    handle = mailbox._deliver_record(record, interface=self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
            "    interface._publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n",
            "    handle = mailbox._deliver_record(record, interface=self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
            "    interface._publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    Exception in thread NetStatThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 268, in check_network_status\n",
            "    self._loop_check_status(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
            "    local_handle = request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 848, in deliver_network_status\n",
            "    return self._deliver_network_status(status)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 510, in _deliver_network_status\n",
            "    return self._deliver_record(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n",
            "    handle = mailbox._deliver_record(record, interface=self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
            "    interface._publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240407_192639-otmejofu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed23d015/DL_Assignment_2/runs/otmejofu' target=\"_blank\">fanciful-sweep-1</a></strong> to <a href='https://wandb.ai/ed23d015/DL_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed23d015/DL_Assignment_2' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed23d015/DL_Assignment_2/runs/otmejofu' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/runs/otmejofu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:lightning_fabric.utilities.distributed:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
            "INFO:lightning_fabric.utilities.distributed:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c30c463a2746424a99b918b6eb6088cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fanciful-sweep-1</strong> at: <a href='https://wandb.ai/ed23d015/DL_Assignment_2/runs/otmejofu' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/runs/otmejofu</a><br/> View project at: <a href='https://wandb.ai/ed23d015/DL_Assignment_2' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240407_192639-otmejofu/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run otmejofu errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-10-345e65ee6910>\", line 84, in sweep_train\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer1.fit(model, train_loader, val_loader)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     call._call_and_handle_interrupt(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 144, in launch\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     while not process_context.join():\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 158, in join\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m -- Process 0 terminated with the following error:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     fn(i, *args)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = function(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 943, in _run\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.strategy.setup_environment()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 154, in setup_environment\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.setup_distributed()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 203, in setup_distributed\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/distributed.py\", line 291, in _init_dist_connection\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py\", line 86, in wrapper\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     func_return = func(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 1177, in init_process_group\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     store, rank, world_size = next(rendezvous_iterator)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 246, in _env_rendezvous_handler\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 174, in _create_c10d_store\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return TCPStore(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:54597 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:54597 (errno: 98 - Address already in use).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eov545r9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normal: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: [3, 3, 3, 5, 5]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape: [3, 224, 224]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_classes: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filter: [64, 64, 64, 64, 64]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240407_192658-eov545r9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed23d015/DL_Assignment_2/runs/eov545r9' target=\"_blank\">major-sweep-2</a></strong> to <a href='https://wandb.ai/ed23d015/DL_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed23d015/DL_Assignment_2' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed23d015/DL_Assignment_2/runs/eov545r9' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/runs/eov545r9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:lightning_fabric.utilities.distributed:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
            "INFO:lightning_fabric.utilities.distributed:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de7d3822c5454b31a19594e88e6c7be6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">major-sweep-2</strong> at: <a href='https://wandb.ai/ed23d015/DL_Assignment_2/runs/eov545r9' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/runs/eov545r9</a><br/> View project at: <a href='https://wandb.ai/ed23d015/DL_Assignment_2' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240407_192658-eov545r9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run eov545r9 errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-10-345e65ee6910>\", line 84, in sweep_train\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer1.fit(model, train_loader, val_loader)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     call._call_and_handle_interrupt(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 144, in launch\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     while not process_context.join():\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 158, in join\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m -- Process 0 terminated with the following error:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     fn(i, *args)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = function(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 943, in _run\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.strategy.setup_environment()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 154, in setup_environment\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.setup_distributed()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 203, in setup_distributed\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/distributed.py\", line 291, in _init_dist_connection\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py\", line 86, in wrapper\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     func_return = func(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 1177, in init_process_group\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     store, rank, world_size = next(rendezvous_iterator)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 246, in _env_rendezvous_handler\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 174, in _create_c10d_store\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return TCPStore(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:54597 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:54597 (errno: 98 - Address already in use).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wvbq4id4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: elu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normal: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: [3, 3, 3, 5, 5]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape: [3, 224, 224]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_classes: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filter: [32, 32, 32, 32, 32]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240407_192713-wvbq4id4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed23d015/DL_Assignment_2/runs/wvbq4id4' target=\"_blank\">genial-sweep-3</a></strong> to <a href='https://wandb.ai/ed23d015/DL_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed23d015/DL_Assignment_2' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/sweeps/b3qcwh7b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed23d015/DL_Assignment_2/runs/wvbq4id4' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/runs/wvbq4id4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:lightning_fabric.utilities.distributed:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
            "INFO:lightning_fabric.utilities.distributed:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8bd36406b354275becdd3dabd8e63a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">genial-sweep-3</strong> at: <a href='https://wandb.ai/ed23d015/DL_Assignment_2/runs/wvbq4id4' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2/runs/wvbq4id4</a><br/> View project at: <a href='https://wandb.ai/ed23d015/DL_Assignment_2' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240407_192713-wvbq4id4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run wvbq4id4 errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-10-345e65ee6910>\", line 84, in sweep_train\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer1.fit(model, train_loader, val_loader)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     call._call_and_handle_interrupt(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 144, in launch\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     while not process_context.join():\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 158, in join\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m -- Process 0 terminated with the following error:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     fn(i, *args)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = function(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 943, in _run\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.strategy.setup_environment()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 154, in setup_environment\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.setup_distributed()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 203, in setup_distributed\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/distributed.py\", line 291, in _init_dist_connection\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py\", line 86, in wrapper\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     func_return = func(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 1177, in init_process_group\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     store, rank, world_size = next(rendezvous_iterator)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 246, in _env_rendezvous_handler\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 174, in _create_c10d_store\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return TCPStore(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:54597 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:54597 (errno: 98 - Address already in use).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7d6e15b67850>> (for post_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BrokenPipeError",
          "evalue": "[Errno 32] Broken pipe",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#  noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class MyLightningModule(pl.LightningModule):\n",
        "    def __init__(self, model, criterion, optimizer):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.forward(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.forward(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return self.optimizer\n",
        "\n",
        "def sweep_train():\n",
        "    # Initialize wandb run\n",
        "    wandb.init(project='DL_Assignment_2', entity='ed23d015')\n",
        "\n",
        "    # Fetch the default configuration from wandb\n",
        "    config = wandb.config\n",
        "\n",
        "    # Set up data loaders based on configuration\n",
        "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_data, batch_size=config.batch_size, pin_memory=True, num_workers=4)\n",
        "\n",
        "    # Initialize model, criterion, and optimizer\n",
        "    model = ...\n",
        "    criterion = ...\n",
        "    optimizer = ...\n",
        "\n",
        "    # Initialize PyTorch Lightning module\n",
        "    lightning_module = MyLightningModule(model, criterion, optimizer)\n",
        "\n",
        "    # Initialize PyTorch Lightning Trainer\n",
        "    trainer = pl.Trainer(max_epochs=10, gpus=1 if torch.cuda.is_available() else None, progress_bar_refresh_rate=30, callbacks=[pl.callbacks.EarlyStopping(monitor='val_loss')])\n",
        "\n",
        "    # Train the model\n",
        "    trainer.fit(lightning_module, train_loader, val_loader)\n",
        "\n",
        "    # Test the model\n",
        "    trainer.test(lightning_module, val_loader)\n",
        "\n",
        "# Run the wandb sweep\n",
        "sweep_id = wandb.sweep(sweep_config, entity='ed23d015', project=\"DL_Assignment_2\")\n",
        "wandb.agent(sweep_id, function=sweep_train, count=120)\n"
      ],
      "metadata": {
        "id": "goZ135D4Yigw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sweep_train():\n",
        "    # Initialize wandb run\n",
        "    wandb.init(project='DL_Assignment_2', entity='ed23d015')\n",
        "\n",
        "    # Fetch the default configuration from wandb\n",
        "    config = wandb.config\n",
        "\n",
        "    # Set up data loaders based on configuration\n",
        "    train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_data, batch_size=config.batch_size, pin_memory=True, num_workers=4)\n",
        "\n",
        "    # Initialize model, criterion, and optimizer\n",
        "    model = ...\n",
        "    criterion = ...\n",
        "    optimizer = ...\n",
        "\n",
        "    # Initialize PyTorch Lightning module\n",
        "    lightning_module = MyLightningModule(model, criterion, optimizer)\n",
        "\n",
        "    # Initialize PyTorch Lightning Trainer\n",
        "    trainer = pl.Trainer(max_epochs=10, gpus=1 if torch.cuda.is_available() else None, progress_bar_refresh_rate=30, callbacks=[pl.callbacks.EarlyStopping(monitor='val_loss')])\n",
        "\n",
        "    # Train the model\n",
        "    trainer.fit(lightning_module, train_loader, val_loader)\n",
        "\n",
        "    # Test the model\n",
        "    trainer.test(lightning_module, val_loader)\n",
        "\n",
        "# Run the wandb sweep\n",
        "sweep_id = wandb.sweep(sweep_config, entity='ed23d015', project=\"DL_Assignment_2\")\n",
        "wandb.agent(sweep_id, function=sweep_train, count=120)"
      ],
      "metadata": {
        "id": "jRElMrZCXgro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2nd try"
      ],
      "metadata": {
        "id": "xQb22jq_Xoqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Ensure model and data loaders are moved to appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(trainer1.max_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{trainer1.max_epochs}'):\n",
        "        # Move data to device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update training loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate training accuracy\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    # No need for gradients during validation\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            # Move data to device\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Update validation loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate validation accuracy\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # Log metrics to wandb\n",
        "    wandb.log({\"epoch\": epoch + 1, \"train_loss\": train_loss, \"train_accuracy\": train_accuracy, \"val_loss\": val_loss, \"val_accuracy\": val_accuracy})\n",
        "\n",
        "    # Print training progress\n",
        "    print(f\"Epoch {epoch + 1}/{trainer1.max_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "# Test the model\n",
        "trainer1.test(test_dataloaders=val_loader)\n"
      ],
      "metadata": {
        "id": "7WUQ7-8PUxsi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}